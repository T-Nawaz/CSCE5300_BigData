{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "## Student Information\n",
    "### Name: Tanzim Nawaz\n",
    "### ID: 11834685"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem Statement\n",
    "The goal of this assignment is simulate the ranking process of web search results while utilizing a different method than the one outlined in the paper. The data used here is not real search engine data, but rather synthetic data generated by code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methodology\n",
    "\n",
    "## How Simulated Data Was Generated\n",
    "The simulated data represents web pages, each with a unique ID and a randomly assigned relevance score. I generated 34,279 such pages, matching the paper, with scores varying uniformly between -80000 and 50000, also matching the paper.\n",
    "\n",
    "## How Your Ranking Method Works and How It Differs from K-Winners-Take-All\n",
    "\n",
    "My ranking method uses a Min-Heap to efficiently find the top 20 most important web pages. It differs significantly from a K-Winners-Take-All (K-WTA) model described in the paper. A K-WTA model typically involves a competitive neural network or iterative process where 'k' neurons (or elements) \"win\" by suppressing others. It's often complex, potentially involving dynamic systems or spike trains, as suggested by the paper's title. In contrast, the Min-Heap method is a standard data structure algorithm, purely based on comparisons and heap operations, without any neural network or iterative \"winning\" mechanisms. It's a direct, non-iterative selection process focused on maintaining the 'k' largest elements seen so far.\n",
    "\n",
    "## The Logic and Steps Used (Min-Heap)\n",
    "\n",
    "- Initialize a Min-Heap: A min-heap data structure is created to store the 20 most important pages found so far. The heap stores tuples of (score, page_id), with the smallest score always at the top.\n",
    "\n",
    "- Iterate Through Pages: Each of the simulated web pages is processed one by one.\n",
    "\n",
    "- Fill the Heap (Initial Phase): If the heap contains fewer than 20 pages, the current page's (score, page_id) is added directly to the heap.\n",
    "\n",
    "- Maintain Top 20 (Main Phase): Once the heap is full (contains 20 pages), the current page's score is compared with the score of the page at the top of the heap (which is the lowest score among the current top 20).\n",
    "\n",
    "If the current page's score is higher than the smallest score in the heap, the smallest element is removed from the heap, and the current page is added.\n",
    "\n",
    "If the current page's score is not higher, it's simply ignored as it's not among the most important 20.\n",
    "\n",
    "- Final Results: After processing all 1000+ pages, the min-heap contains the 20 most important pages. These are then extracted and sorted in descending order of score for presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eZ2Kte4FXdHU",
    "outputId": "1c6d6808-2905-408a-b9f1-53ffcfb42b05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulating 10000 web pages\n",
      "Finding the top 20 most important pages using a Min-Heap\n",
      "\n",
      "Results\n",
      "Top 20 Web Pages (Ranked by Score):\n",
      "1. webpage_2010 (Score: 49969.56)\n",
      "2. webpage_7448 (Score: 49963.21)\n",
      "3. webpage_8462 (Score: 49957.94)\n",
      "4. webpage_5563 (Score: 49923.67)\n",
      "5. webpage_8752 (Score: 49918.54)\n",
      "6. webpage_9368 (Score: 49879.92)\n",
      "7. webpage_4903 (Score: 49872.52)\n",
      "8. webpage_7801 (Score: 49867.31)\n",
      "9. webpage_6986 (Score: 49867.29)\n",
      "10. webpage_5872 (Score: 49865.39)\n",
      "11. webpage_5778 (Score: 49857.80)\n",
      "12. webpage_7479 (Score: 49844.00)\n",
      "13. webpage_944 (Score: 49831.90)\n",
      "14. webpage_5436 (Score: 49818.01)\n",
      "15. webpage_2175 (Score: 49816.89)\n",
      "16. webpage_1733 (Score: 49803.85)\n",
      "17. webpage_4564 (Score: 49781.42)\n",
      "18. webpage_6163 (Score: 49725.21)\n",
      "19. webpage_8182 (Score: 49721.89)\n",
      "20. webpage_2365 (Score: 49719.92)\n",
      "\n",
      "Time Taken: 0.5050 milliseconds\n",
      "Number of Iterations/Operations (Approx.): 10000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import heapq\n",
    "import time\n",
    "\n",
    "def synthetic_web_page_with_ranking(num_pages=1000):\n",
    "    \"\"\"\n",
    "    Simulates web pages with random relevance scores.\n",
    "    Each page is represented as a tuple: (id, score)\n",
    "    \"\"\"\n",
    "    pages = []\n",
    "    for i in range(num_pages):\n",
    "        # Simulate score between -80000 and 50000 as stated in the paper\n",
    "        score = random.uniform(-80000, 50000)\n",
    "        pages.append({'id': f'webpage_{i+1}', 'score': score})\n",
    "    return pages\n",
    "\n",
    "def sort_ranking(pages, k=20):\n",
    "    \"\"\"\n",
    "    Finds the top K pages using a min-heap.\n",
    "    The heap stores (score, page_object) to keep track of the lowest score\n",
    "    among the top K, allowing us to compare new pages efficiently.\n",
    "    \"\"\"\n",
    "    min_heap = []\n",
    "    iterations = 0\n",
    "\n",
    "    for page in pages:\n",
    "        iterations += 1\n",
    "\n",
    "        if len(min_heap) < k:\n",
    "            # If heap is not full, add the page\n",
    "            heapq.heappush(min_heap, (page['score'], page['id']))\n",
    "        else:\n",
    "            # If heap is full, check if current page's score is greater than the smallest in heap\n",
    "            if page['score'] > min_heap[0][0]:\n",
    "                # Remove the smallest\n",
    "                heapq.heappop(min_heap)\n",
    "                # Add the new larger score\n",
    "                heapq.heappush(min_heap, (page['score'], page['id']))\n",
    "\n",
    "    top_k_results = sorted(min_heap, key=lambda x: x[0], reverse=True)\n",
    "    # Convert back to a more readable format for output\n",
    "    results = [{'id': page_id, 'score': score} for score, page_id in top_k_results]\n",
    "\n",
    "    return results, iterations\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    num_pages = 10000\n",
    "    top_k = 20\n",
    "\n",
    "    print(f\"Simulating {num_pages} web pages\")\n",
    "    web_pages = synthetic_web_page_with_ranking(num_pages)\n",
    "\n",
    "    print(f\"Finding the top {top_k} most important pages using a Min-Heap\\n\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    top_20_pages, operations_count = sort_ranking(web_pages, top_k)\n",
    "    end_time = time.perf_counter()\n",
    "\n",
    "    time_taken = (end_time - start_time) * 1000\n",
    "\n",
    "    print(\"Results\")\n",
    "    print(f\"Top {top_k} Web Pages (Ranked by Score):\")\n",
    "    for i, page in enumerate(top_20_pages):\n",
    "        print(f\"{i+1}. {page['id']} (Score: {page['score']:.2f})\")\n",
    "\n",
    "    print(f\"\\nTime Taken: {time_taken:.4f} milliseconds\")\n",
    "    print(f\"Number of Iterations/Operations (Approx.): {operations_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "My method, using a Min-Heap, provides a straightforward and efficient way to rank and select the top 20 web search results from a large dataset. What I learned is that for specific \"top K\" problems, algorithms tailored to selection (like heap-based methods) can be highly effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
